---
title: "计组概述"
date: 2025-09-12  # 文章发布时间
categories: [计算机组织与结构] # 你的分类
tags: [笔记]     # 你的标签
---
# 概述

### 什么是计算机？

“通用电子数字计算机”

数字：离散的，非连续的

### 组织与结构

组织：对编程人员不可见（如：是**如何实现**乘法指令的，包括控制信号、存储技术）

结构：对编程人员可见（如：字长是16位还是32位；**是否有**乘法指令【而不是要使用加法指令和循环】）

> [!TIP]
>
> 组织相同，结构不同？---提供不同的指令集
>
> 结构相同，组织不同？---提供相同的指令，但实现不同

### 计算机pick shit

#### 第一代：真空管

冯诺依曼结构：存储程序的思想

> [!IMPORTANT]
>
> ## 冯诺依曼结构
>
> ### 基本原则
>
> 计算机由运算器、存储器、控制器、输入设备、输出设备组成
>
> <img src="https://github.com/HEYWEEN/HEYWEEN.github.io/blob/master/assets/images/posts/image-20250906161429130.png" alt="image-20250906161429130" style="zoom:50%;" />
>
> 1. 主存储器：地址和存储的内容
>
> 2. 算术逻辑单元 / 处理单元：执行信息的实际处理
>
> 3. 程序控制单元 / 控制单元：指挥信息的处理
>
> 4. 输入设备：将信息送入计算机中
>
> 5. 输出设备：将处理结果以某种形式显示在计算机外
>
> 
>
> ### **存储程序思想（Stored-Program Concept）**
>
> #### 一、核心思想：什么是“存储程序思想”？
>
> **存储程序思想**的精髓可以概括为一句话：
>
> > **将程序指令和数据一起存储在同一个存储器中，计算机通过自动依次执行存储器中的指令来处理数据。**
>
> 让我们来拆解这个定义中的几个革命性要点：
>
> 1.  **程序像数据一样被存储**：
>     *   在早期的计算机（如ENIAC）中，程序是通过物理方式（如插拔线缆、设置开关）来设定的，改变程序意味着重新布线，非常麻烦。
>     *   冯·诺依曼结构下，程序被转换成二进制代码，**和待处理的数据一样，被存入内存**。这意味着程序变成了可动态改变的“软件”，而不再是固定的“硬件”。
>
> 2.  **指令和数据地位等同**：
>     *   在内存里，你无法从外表区分一段二进制代码到底是**指令**（告诉CPU做什么）还是**数据**（被操作的对象）。
>     *   它们都被一视同仁地存储，都可以被读写。
>
> 3.  **按地址寻址**：
>     *   内存被划分为许多单元，每个单元都有一个唯一的**地址**。
>     *   CPU通过地址来访问内存，要么取出一条指令，要么读写一个数据。
>
> 4.  **顺序执行（核心执行模式）**：
>     *   CPU内部有一个关键的寄存器——**程序计数器（PC, Program Counter）**。
>     *   PC总是保存着**下一条要执行的指令的地址**。
>     *   CPU的工作流程是一个循环（**取指-译码-执行-回写**循环）：
>         1.  **取指（Fetch）**：根据PC中的地址，从内存中取出指令。
>         2.  **译码（Decode）**：分析这条指令，知道要做什么操作（如加法），操作数在哪里。
>         3.  **执行（Execute）**：执行这个操作（如从内存取数据，在ALU中计算）。
>         4.  **回写（Write-back）**：将结果写回寄存器或内存。
>     *   **执行完一条指令后，PC通常会自动加1，指向下一条指令的地址**，从而实现顺序执行。跳转指令（如if、循环）会改变PC的值，打破顺序。
>
> ---
>
> #### 二、如何区分指令和数据？
>
> 这是一个非常经典的问题。既然指令和数据混在一起存储，CPU怎么知道它从内存里取出来的是指令还是数据呢？
>
> 答案是：**由上下文和CPU的执行状态决定，而不是由二进制代码本身决定。**
>
> 1.  **取指阶段**：
>     *   当CPU将**程序计数器（PC）** 中的地址发送到内存时，它期望从该地址**取回的是指令**。
>     *   在这个时刻，从数据总线传来的二进制流被CPU**当作指令**送入**指令寄存器（IR）**，然后进行译码。
>
> 2.  **执行阶段（访存）**：
>     *   当CPU执行一条需要从内存读写数据的指令（如`LOAD R1, [1000]`，意思是将内存地址1000的数据加载到寄存器R1）时，它会将地址1000发送到内存。
>     *   在这个时刻，从数据总线传来的二进制流被CPU**当作数据**来处理，并放入指定的寄存器。
>
> **关键区别在于：**
>
> *   **是PC指向的地址，还是指令中指定的操作数地址？**
> *   **CPU在取指周期取回的就是指令，在执行周期的访存操作中取回的就是数据。** 同一段二进制数，如果被PC指向，它就是指令；如果被一条指令的操作数指向，它就是数据。
>
> #### 三、冯·诺依曼结构的五大部件
>
> 存储程序思想体现在一个由五大部件组成的结构模型中：
>
> 1.  **运算器（ALU, Arithmetic Logic Unit）**：负责执行所有的算术和逻辑运算。
> 2.  **控制器（CU, Control Unit）**：指挥协调其他部件工作，核心是解释执行指令。
> 3.  **存储器（Memory）**：核心部件，用于**统一存储程序和数据**。
> 4.  **输入设备（Input Device）**：将程序和数据输入计算机。
> 5.  **输出设备（Output Device）**：将处理结果输出。
>
> **数据流**和**指令流**都通过同一组总线（Bus）在存储器和CPU之间传输，这也是该结构有时被称为“冯·诺依曼瓶颈”的原因。
>
> ---
>
> #### 四、历史意义与局限性
>
> ##### 意义：
>
> *   **通用性**：使计算机成为通用机器，只需更换存储器中的程序就能解决不同问题，无需重新设计硬件。
> *   **自动化**：实现了程序的自动执行，奠定了软件产业的基础。
> *   **里程碑**：明确了计算机的基本结构，此后的计算机基本都是“冯·诺依曼机”。
>
> ##### 局限性（冯·诺依曼瓶颈）：
>
> *   **共享通路**：指令和数据共享同一套总线（数据/地址总线）和存储器。这意味着CPU在**一个时钟周期内，不能同时取指令和取数据**。
> *   **性能限制**：高速的CPU常常需要等待相对慢速的内存传输指令和数据，限制了系统性能的进一步提升。
>
> ##### 现代演变：
>
> 为了解决瓶颈，现代计算机采用了大量改进技术，但其核心思想仍未改变：
>
> *   **Cache（缓存）**：在CPU和主存之间增加高速小容量缓存，存放最常用的指令和数据。
> *   **哈佛架构（Harvard Architecture）**：在核心层面（如CPU内部）使用**独立的指令总线和数据总线**，可以同时取指和取数。这是冯氏结构的重要演变。很多现代处理器（如ARM）采用了一种“改进型哈佛架构”，在CPU外部共享总线，在内部核心使用独立总线。

#### 第二代：晶体管

把所有真空管换成晶体管，改变的是组织而不是结构

但是组织上的改变会促使结构上的改变

#### 第三代及后续几代：集成电路

#### 摩尔定律（目标而不是规律）

单芯片上所能包含的晶体管数量每年翻一番 (1965-1969)/1970 年起减慢为每 18 个月翻一番

> [!NOTE]
>
> 为什么摩尔定律对于软院同学来说很重要？



## 计算机发展：不变与变

![image-20250905145337706](https://github.com/HEYWEEN/HEYWEEN.github.io/blob/master/assets/images/posts/image-20250905145337706.png)

### 1. 基本功能（不变）

计算机的基本功能始终包括：

- **数据处理**：对数据进行运算和转换。
- **数据传输**：在计算机内部或与外部设备之间传输数据。
- **数据存储**：将数据保存在存储器中供后续使用。
- **控制**：协调各个部件的工作。
- **操作环境**：提供数据的输入和输出接口。

这些功能是计算机系统的核心，不随技术发展而改变。

---

### 2. 运算速度（变化）

计算机的运算速度随着技术的发展显著提升。以下是各发展阶段及其典型速度：

| 发展阶段 | 时间      | 技术              | 典型速度（操作次数/秒） |
| -------- | --------- | ----------------- | ----------------------- |
| 1        | 1946–1957 | 真空管            | 40,000                  |
| 2        | 1958–1964 | 晶体管            | 200,000                 |
| 3        | 1965–1971 | 小/中规模集成电路 | 1,000,000               |
| 4        | 1972–1977 | 大规模集成电路    | 10,000,000              |
| 5        | 1978–1991 | 超大规模集成电路  | 100,000,000             |
| 6        | 1991–现在 | 巨大规模集成电路  | 1,000,000,000           |

---

## 计算机性能评价

### 1. 关键性能参数

- **性能**：执行任务的速度
- **成本**：硬件和软件的成本
- **尺寸**：物理大小
- **安全性**：系统安全等级
- **可靠性**：系统稳定运行的能力
- **能耗**：功耗效率

---

### 2. CPU性能评价指标

#### a. 时钟频率与时钟周期

- **时钟频率（f）**：单位赫兹（Hz），表示每秒的时钟周期数。

- **时钟周期（t）**：每个周期的时间，单位为秒（s），满足：
  $$
  t = \frac{1}{f}
  $$

> [!TIP]
>
> ## **时钟周期（Clock Cycle）** 
>
> ---
>
> ### 一、核心概念：什么是时钟周期？
>
> 想象一下乐团演奏。指挥家以稳定的节奏挥舞指挥棒，每个节拍都告诉乐手们何时开始演奏下一个音符。**时钟周期**就是计算机中这个“节拍”。
>
> 1.  **定义**：
>     *   时钟周期是**CPU中最小、最基本的时间单位**。
>     *   它是系统时钟（System Clock）发出两个相邻电子脉冲之间的时间间隔。
>     *   你可以把它理解为CPU工作的“心跳”或“节奏”。
> 2.  **单位**：
>     *   通常以**纳秒（ns）** 或**皮秒（ps）** 为单位。
>     *   例如，一个时钟周期为 0.5 ns。
> 3.  **与时钟频率的关系**：
>     *   时钟周期（`t`）和时钟频率（`f`，即我们常说的主频，如 3.5 GHz）是**互为倒数**的关系。
>
> ---
>
> ### 二、时钟周期的作用：同步
>
> CPU由数百万甚至数十亿个晶体管组成。为了完成一条指令（比如加法），需要多个部件（取指令、解码、执行、写回结果）协同工作。
>
> *   **时钟周期提供了同步信号**：它确保所有部件都按照统一的步调操作。在一个时钟周期内，每个部件完成自己那部分微小的、预先设计好的任务。
> *   **类似于工厂流水线**：传送带每移动一次（一个时钟周期），每个工位上的工人就完成一道工序。没有这个统一的节奏，整个流水线就会陷入混乱。
>
> ---
>
> ### 三、时钟周期与指令执行（关键！）
>
> 这是理解CPU性能的核心。
>
> 1. **CPI（Cycles Per Instruction）**：
>
>    *   不同的指令需要的工作量不同，因此所需的时钟周期数也不同。
>     *   **CPI** 就是指**执行一条指令平均需要的时钟周期数**。
>    *   例如，一个简单的加法指令可能在1个周期内完成，而一个复杂的除法指令可能需要10个甚至更多周期。
>
> 2. **程序执行时间公式**：
>    要计算一个程序运行了多久，可以使用这个核心公式：
>    **`T = I_c × CPI × t`**
>
>     *   **`T`**：程序执行的总时间（秒，s）
>     *   **`I_c`**：程序需要执行的**指令总条数**
>     *   **`CPI`**：执行这些指令的**平均时钟周期数**
>    *   **`t`**：**时钟周期**（秒，s）
>
>     **这个公式告诉我们，CPU的性能（程序执行时间`T`）由三个关键因素决定：**
>
>     *   **`I_c`**：**软件算法**和**编译器**的影响。好的算法和编译器能生成更短的指令序列。
>    *   **`CPI`**：**CPU指令集架构（ISA）** 和**微架构设计**的影响。设计高效的CPU核心可以降低CPI。
>     *   **`t`**：**半导体工艺**和**电路设计**的影响。工艺越先进，时钟周期`t`越短，主频`f`越高。
>
> ---
>
> ### 四、举例说明
>
> 假设我们有两台电脑，运行同一个程序（`I_c = 10亿条指令`）。
>
> *   **CPU A**：主频 `f_A = 4 GHz`，平均 `CPI_A = 1.5`
> *   **CPU B**：主频 `f_B = 3 GHz`，平均 `CPI_B = 1.0`
>
> 问：哪个CPU更快？快多少？
>
> **计算过程：**
>
> 1.  **计算时钟周期 `t`**：
>     *   `t_A = 1 / 4GHz = 0.25 ns`
>     *   `t_B = 1 / 3GHz ≈ 0.333 ns`
>
> 2.  **计算执行时间 `T`**：
>     *   `T_A = I_c × CPI_A × t_A = 1e9 × 1.5 × 0.25e-9 = 0.375 秒`
>      *   `T_B = I_c × CPI_B × t_B = 1e9 × 1.0 × 0.333e-9 ≈ 0.333 秒`
>
> **结论**：虽然CPU A的主频更高，但因为CPU B的**架构更高效**（平均每条指令只需1个周期，即CPI更低），所以**CPU B的性能反而更好**，程序运行时间更短。
>
> 这个例子清晰地表明，**不能只看主频（时钟频率）来评判CPU性能**，必须结合**CPI**和**指令条数**综合考量。这就是时钟周期`t`在性能模型中的核心意义。
>
> ---
>
> ### 总结
>
> | 概念             | 定义                     | 符号  | 单位            | 意义                                |
> | :--------------- | :----------------------- | :---- | :-------------- | :---------------------------------- |
> | **时钟周期**     | CPU工作的基本时间单位    | `t`   | 秒（s）, ns, ps | CPU的“心跳”，同步所有操作           |
> | **时钟频率**     | 每秒的时钟周期数         | `f`   | Hz（赫兹）      | 常说的“主频”，`f = 1/t`             |
> | **CPI**          | 每条指令所需的平均周期数 | `CPI` | 周期数/指令     | 衡量CPU架构效率的关键指标           |
> | **程序执行时间** | 运行完程序所需的总时间   | `T`   | 秒（s）         | `T = I_c × CPI × t`，性能的最终体现 |

#### b. CPI（Cycles Per Instruction）

- 表示执行一条指令所需的平均时钟周期数。

- 若程序中有多种指令类型，则：
  $$
  CPI = \frac{\sum_{i=1}^{n} (CPI_i \times I_i)}{I_c}
  $$
  其中：

  - \(IcI_c\) ：总指令数
  - \(IiI_i\) ：第 i 类指令的数量
  - \(CPIiCPI_i\) ：第 i 类指令所需的周期数

#### c. 程序执行时间

$$
T = I_c \times CPI \times t
$$

#### d. MIPS（Million Instructions Per Second）

$$
MIPS = \frac{I_c}{T \times 10^6} = \frac{f}{CPI \times 10^6}
$$

#### e. MFLOPS（Million Floating Point Operations Per Second）

$$
MFLOPS = \frac{N_{floating-point \, op}}{T \times 10^6}
$$

---

### 3. 基准程序（Benchmark）

用于测量系统性能的标准程序集。

- **算术平均值**：
  $$
  R_A = \frac{1}{m} \sum_{i=1}^m R_i
  $$

- **调和平均值**（更适合衡量速率类指标）：
  $$
  R_H = \frac{m}{\sum_{i=1}^m \frac{1}{R_i}}
  $$

---

## 性能设计的基本原则

### 1. 大概率事件优先原则

- 对最常见的事件（高频率发生的事件）优先优化，以获得最大的整体性能提升。

### 2. Amdahl定律

- 系统性能提升的上限受限于被优化部分在系统中的占比。

- 公式：
  $$
  S = \frac{1}{(1 - f) + \frac{f}{k}}
  $$
  其中：

  - \(SS\) ：系统加速比
  - \(ff\) ：可优化部分所占比例
  - \(kk\) ：该部分性能提升的倍数

- **含义**：即使某部分性能提升极大（\(k→∞k \to \infty\) ），系统整体加速比也不会超过 \(11−f\frac{1}{1 - f}\)。



# 计算机的顶层视图

<img src="https://github.com/HEYWEEN/HEYWEEN.github.io/blob/master/assets/images/posts/image-20250906165833770.png" alt="image-20250906165833770" style="zoom:50%;" />

## 计算机工作原理

<img src="https://github.com/HEYWEEN/HEYWEEN.github.io/blob/master/assets/images/posts/image-20250906165910222.png" alt="image-20250906165910222" style="zoom:67%;" />

1. 指令和数据存储在单个读写存储器中
2. 主存中的内容按位置访问，无需考虑其中包含的类型
3. CPU从一条指令到下一条指令以顺序方式执行，除非明确修改
4. I/O模块与CPU、主存交换计算机系统外部的数据

> [!TIP]
>
> **不成比例扩展效应**指的是：在计算机系统中，当某个部件（如CPU）的性能得到显著提升时，其他相关部件（如内存、硬盘、总线）的性能**并未以同等比例提升**，从而导致系统整体性能的提升幅度**远低于**该部件自身的提升幅度。
>
> 简单来说就是：**一条腿跑得快，另一条腿跟不上，整体速度还是被慢腿拖累了。**
>
> 这个效应是**Amdahl定律（阿姆达尔定律）** 在硬件层面的一个具体体现和延伸。Amdahl定律指出：系统优化后的整体加速比，受限于被优化部分在原系统计算时间中所占的比例。
>
> 例：CPU与内存的速度鸿沟

<img src="https://github.com/HEYWEEN/HEYWEEN.github.io/blob/master/assets/images/posts/image-20250906170613071.png" alt="image-20250906170613071" style="zoom:50%;" />

## 核心问题与解决方案详解

#### 问题1：CPU的频率不能无限提高

*   **问题描述**：
    *   **理论限制**：晶体管开关、信号传输均需要时间，时钟脉冲必须持续足够长以保证同步。
    *   **物理限制**：芯片面积增大导致**连线延迟**显著；频率越高，**功耗和散热**越大（功耗墙）。

*   **解决方案**：**改进CPU芯片结构**
    *   不再单纯追求提高主频，而是通过改变内部架构来提升效率。
    *   **关键技术**：指令流水线（Instruction Pipelining）、多核（Multi-core）、超标量（Superscalar）等架构技术，旨在**在每个时钟周期内完成更多工作**，而非无限缩短周期时间。
    *   **对应章节**：第14讲（指令周期和指令流水线）

---

#### 问题2：内存墙（Memory Wall）的存在

*   **问题描述**：
    *   CPU处理速度（逻辑）的增长速度**远快于**主存（DRAM）访问速度的增长。
    *   高速CPU需要花费大量时间“等待”慢速的内存传送数据和指令，性能被严重浪费。

*   **解决方案**：**采用高速缓存（Cache）**
    *   在CPU和主存之间加入一小块**高速静态RAM（SRAM）** 作为缓存。
    *   **原理**：利用**局部性原理**，将CPU近期可能访问的数据副本存放在Cache中。CPU优先访问Cache，大幅减少访问主存的次数。
    *   **增强措施**：增大总线数据宽度，一次传输更多数据。
    *   **对应章节**：第9讲（高速缓冲存储器）

---

#### 问题3：CPU等待I/O传输数据

*   **问题描述**：
    *   I/O设备（如磁盘、键盘）速度极慢，与CPU速度差距巨大。
    *   如果采用程序控制I/O（ polling），CPU必须不断查询设备状态，导致在等待I/O时**保持空闲**，效率极低。

*   **解决方案**：**采用中断机制（Interrupt）**
    *   **机制**：I/O设备完成工作后，**主动**向CPU发出中断信号。CPU收到信号后，暂停当前程序，转去执行处理该I/O事件的程序（中断服务例程），处理完毕后再返回原程序继续执行。
    *   **优势**：CPU在I/O操作期间可以执行其他任务，极大地提高了利用率。
    *   **高级形式**：**多重中断**（处理中断时允许被更高优先级的中断打断）。
    *   **对应章节**：第13讲（指令系统）、第17讲（输入/输出）

---

#### 问题4：兼顾存储容量、速度和成本

*   **问题描述**：
    *   **需求矛盾**：需要存储器同时具备**大容量**、**高速度**和**低成本**。
    *   **技术现实**：存储技术存在**铁三角**关系——访问时间越短（速度越快），每比特成本越高，容量也越难做大。

*   **解决方案**：**层次式存储结构（Memory Hierarchy）**
    *   **思想**：不依赖单一存储部件，而是构建一个由多级存储器组成的金字塔形层次体系。
    *   **组成**：`寄存器 → L1 Cache → L2 Cache → L3 Cache → 主存 (DRAM) → 固态硬盘 (SSD) → 机械硬盘 (HDD) → ...`
    *   **效果**：从CPU角度看，拥有一个容量近似最大、速度近似最快、成本近似最低的存储系统。系统自动将频繁访问的数据放在高层。
    *   **对应章节**：第8讲（内部存储器）、第9讲（Cache）、第10讲（外部存储器）、第12讲（虚拟存储器）

---

#### 问题5：I/O设备传输速率差异大

*   **问题描述**：
    *   不同I/O设备速度差异巨大（从键盘鼠标到千兆网卡），且都远慢于CPU和内存。

*   **解决方案**：**采用缓冲区和改进I/O操作技术**
    *   **缓冲区（Buffer）**：在I/O模块或内存中开辟一块临时存储区。数据先成块传入缓冲区，再统一处理，平滑速度差异，避免CPU频繁等待。
    *   **改进技术**：包括**程序中断I/O**、**直接存储器访问（DMA）**（I/O设备与主存直接交换数据，无需CPU介入）、**专用I/O处理器（通道）** 等。
    *   **对应章节**：第17讲（输入输出）

---

#### 问题6：计算机部件互连复杂

*   **问题描述**：
    *   早期计算机采用**专线互连**（如IBM 7094），每个部件间都有单独线路，导致系统结构极其复杂、混乱、难以扩展和维护。

*   **解决方案**：**采用总线（Bus）**
    *   **思想**：使用一组**共享的通信通路**来连接所有系统组件。
    *   **优势**：极大地**简化了物理布局和控制系统**，提高了模块化和可扩展性。
    *   **总线分类**：
        *   **数据总线**：在各模块间传送数据。
        *   **地址总线**：指定数据读写的源或目标地址。
        *   **控制总线**：传送控制信号（读/写、中断、时钟等）。
    *   **对应章节**：第16讲（总线）

