---
title: "機器學習基本概念簡介"
date: 2026-01-11  # 文章发布时间
categories: [机器学习] # 你的分类
tags: [笔记]     # 你的标签
math: true

---

## 机器学习是什么：让机器具备寻找函数的能力

![截屏2026-01-18 15.35.07](https://cdn.jsdelivr.net/gh/HEYWEEN/images@main/images%E6%88%AA%E5%B1%8F2026-01-18%2015.35.07.png)

### 不同的类别

Regression：假设函数的输出是一个数值scalar

Classification：选择

### 机器怎么寻找一个函数

**Step1:function with unknown**

**Step2:define loss from training data**

**Step3:optimization**

![截屏2026-01-18 16.35.51](https://cdn.jsdelivr.net/gh/HEYWEEN/images@main/images%E6%88%AA%E5%B1%8F2026-01-18%2016.35.51.png)

### Loss：也是一个函数

输入是model里面的参数，也就是$L(b,w)$

输出就代表了这b,w这组数值有多好

那么应该如何计算呢？---根据训练资料

真实的值叫Label

![截屏2026-01-18 16.42.15](https://cdn.jsdelivr.net/gh/HEYWEEN/images@main/images%E6%88%AA%E5%B1%8F2026-01-18%2016.42.15.png)

### Optimization

$$
w* ,b* =argMinL
$$

Gradient Descent：先假设b不动，看看只有一个参数的情况---随机选择w<sub>0</sub>，计算w对Loss的微分（也就是斜率），如果是负数就增加w，反之减小w，得到w<sub>1</sub>,跨的步子有多大由斜率和learning rate（自己设定）同时决定

![截屏2026-01-18 16.57.08](https://cdn.jsdelivr.net/gh/HEYWEEN/images@main/images%E6%88%AA%E5%B1%8F2026-01-18%2016.57.08.png)

注意：Loss是自己定义的，所以可以是负的

什么时候会停下来？

1. 达到步数上限
2. 找到微分是0的点

但是，不一定会找到真正最好的解global minima，可能只找到局部最优解local minima（其实是一个假议题，这不是我们真正面对的难题）

多个参数，也是一模一样的道理！